{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Classical-Piano-Composer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-njEJDmyS62n",
        "outputId": "5c106065-0e97-4ae8-c2ba-efb6c7b7ad64"
      },
      "source": [
        "!pip install np_utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting np_utils\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/18/5704a782fd72727a9e63198fcc76fadb86975f45bcdf579c10f668329508/np_utils-0.5.12.1.tar.gz (61kB)\n",
            "\r\u001b[K     |█████▍                          | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 20kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 40kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 51kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from np_utils) (1.19.5)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from np_utils) (0.16.0)\n",
            "Building wheels for collected packages: np-utils\n",
            "  Building wheel for np-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np-utils: filename=np_utils-0.5.12.1-cp37-none-any.whl size=57133 sha256=5d61640cb65cd93c3bee19769cc0a814873cc4780b037546b9a5b856f8498d87\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/4b/81/206efd0d01330a96f3aebe5021d2d5f0b264b7ade827c306ef\n",
            "Successfully built np-utils\n",
            "Installing collected packages: np-utils\n",
            "Successfully installed np-utils-0.5.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "wEdLlO6bVG5g",
        "outputId": "626eb3c4-2868-43f8-b9ca-c7b7d4116420"
      },
      "source": [
        "import os\n",
        "os.listdir(\"drive/MyDrive/Music-Generator\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8c8e9a11c6a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/MyDrive/Music-Generator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/Music-Generator'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q1Skxw1lJygO",
        "outputId": "10d5bda1-dbfc-40bc-e67a-91e1f34d9434"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du11j6kWRM9R"
      },
      "source": [
        "\"\"\" This module prepares midi file data and feeds it to the neural\n",
        "    network for training \"\"\"\n",
        "import collections\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import numpy\n",
        "\n",
        "from music21 import converter, instrument, note, chord\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.metrics import *\n",
        "try:\n",
        "  import google.colab\n",
        "  IS_ON_GOOGLE_COLAB = True\n",
        "except:\n",
        "  IS_ON_GOOGLE_COLAB = False\n",
        "\n",
        "TEST_RUN = False\n",
        "NORMALIZE_NOTES = True\n",
        "NORMALIZATION_BOUNDARIES = [3, 4]\n",
        "\n",
        "EPOCHS = 50\n",
        "MODEL_DIR_PATH = \"generated_models/\"\n",
        "MODEL_NAME = \"cpc\"\n",
        "OCCURENCES = \"data/occurences\"\n",
        "DATA_NOTES_DIR = \"data/notes\"\n",
        "MIDI_SONGS_REGEX = \"midi_songs/*.mid\"\n",
        "CHECKPOINTS = \"checkpoints/\"\n",
        "LOGS = \"logs/\"\n",
        "\n",
        "\n",
        "GOOGLE_COLAB_ROOT = \"drive/MyDrive/Music-Generator/\"\n",
        "\n",
        "if IS_ON_GOOGLE_COLAB:\n",
        "    MODEL_DIR_PATH = GOOGLE_COLAB_ROOT + MODEL_DIR_PATH\n",
        "    DATA_NOTES_DIR = GOOGLE_COLAB_ROOT + DATA_NOTES_DIR\n",
        "    MIDI_SONGS_REGEX = GOOGLE_COLAB_ROOT + MIDI_SONGS_REGEX\n",
        "    OCCURENCES = GOOGLE_COLAB_ROOT + OCCURENCES\n",
        "    CHECKPOINTS = GOOGLE_COLAB_ROOT\n",
        "    LOGS = GOOGLE_COLAB_ROOT + LOGS\n",
        "\n",
        "\n",
        "if TEST_RUN:\n",
        "    EPOCHS = 100\n",
        "\n",
        "def train_network(checkpoint_path=None):\n",
        "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
        "    notes = get_notes()\n",
        "    curr_dt = get_current_datetime()\n",
        "    print(str(\"Current datatime: \" + curr_dt))\n",
        "    # get amount of pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "    print(\"Vocabulary size: \" + str(n_vocab))\n",
        "\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    model = create_network(network_input, n_vocab)\n",
        "\n",
        "    if checkpoint_path:\n",
        "      model.load_weights(checkpoint_path)\n",
        "\n",
        "    train(model, network_input, network_output, curr_dt)\n",
        "\n",
        "def normalize_note(pitch: note.Note):\n",
        "    if pitch.octave not in range(NORMALIZATION_BOUNDARIES[0], NORMALIZATION_BOUNDARIES[1]):\n",
        "        if pitch.octave < NORMALIZATION_BOUNDARIES[0]:\n",
        "            pitch.octave = NORMALIZATION_BOUNDARIES[0]\n",
        "        elif pitch.octave > NORMALIZATION_BOUNDARIES[1]:\n",
        "            pitch.octave = NORMALIZATION_BOUNDARIES[1]\n",
        "    return pitch\n",
        "\n",
        "def get_notes():\n",
        "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
        "    notes = []\n",
        "    # max_i = 1\n",
        "    for i, file in enumerate(glob.glob(MIDI_SONGS_REGEX)):\n",
        "        if TEST_RUN and i == 1:\n",
        "            break\n",
        "        midi = converter.parse(file)\n",
        "\n",
        "        print(\"Parsing %s\" % file)\n",
        "\n",
        "        notes_to_parse = None\n",
        "\n",
        "        try: # file has instrument parts\n",
        "            s2 = instrument.partitionByInstrument(midi)\n",
        "            notes_to_parse = s2.parts[0].recurse()\n",
        "        except: # file has notes in a flat structure\n",
        "            notes_to_parse = midi.flat.notes\n",
        "\n",
        "        for element in notes_to_parse:\n",
        "            if isinstance(element, note.Note):\n",
        "                if NORMALIZE_NOTES:\n",
        "                    element = normalize_note(element)\n",
        "                notes.append(str(element.pitch))\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                # notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "                if NORMALIZE_NOTES:\n",
        "                    notes.append('.'.join(str(normalize_note(n)) for n in element.pitches))\n",
        "                else:\n",
        "                    notes.append('.'.join(str(n) for n in element.pitches))\n",
        "\n",
        "    with open(DATA_NOTES_DIR, 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "\n",
        "    return notes\n",
        "\n",
        "def prepare_sequences(notes, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    sequence_length = 100\n",
        "\n",
        "\n",
        "    # get all pitch names\n",
        "    occurences = collections.defaultdict(int)\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    for note in notes:\n",
        "        occurences[note] += 1\n",
        "    # with open('data/occurences', 'wb') as filepath:\n",
        "    #     pickle.dump(occurences, filepath)\n",
        "\n",
        "    jsonStr = json.dumps(occurences)\n",
        "    with open(OCCURENCES, 'w') as f:\n",
        "        f.writelines(jsonStr)\n",
        "     # create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)\n",
        "\n",
        "def create_network(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop',  metrics=[CategoricalAccuracy()])\n",
        "    return model\n",
        "\n",
        "def get_current_datetime():\n",
        "    from datetime import datetime\n",
        "    now = datetime.now()\n",
        "    dt_name = now.strftime(\"%m_%d_%Y__%H_%M_%S\")\n",
        "    return dt_name\n",
        "\n",
        "def train(model, network_input, network_output, curr_dt):\n",
        "    \"\"\" train the neural network \"\"\"\n",
        "    # filepath = CHECKPOINTS + \"weights-improvement-{epoch:02d}-{loss:.4f}-{categorical_accuracy:.4f}-bigger.hdf5\"\n",
        "    # filepath = \"weights-improvement-epoch:{epoch:02d}-loss:{loss:.4f}-cat_acc:{categorical_accuracy:.4f}.hdf5\"\n",
        "    filepath =  CHECKPOINTS + str(curr_dt) + \"/\" + \"epoch:{epoch:02d}-loss:{loss:.4f}-cat_acc:{categorical_accuracy:.4f}.hdf5\"\n",
        "\n",
        "    # filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='categorical_accuracy',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='max'\n",
        "    )\n",
        "    log = tf.keras.callbacks.TensorBoard(log_dir=LOGS + curr_dt),\n",
        "     \n",
        "    callbacks_list = [checkpoint, log]\n",
        "\n",
        "\n",
        "    history = model.fit(network_input, network_output, epochs=EPOCHS, batch_size=128, callbacks=callbacks_list)\n",
        "    print(history.history)\n",
        "    print(MODEL_DIR_PATH + MODEL_NAME + \"_\" + curr_dt + \".hdf5\")\n",
        "    model.save(MODEL_DIR_PATH + MODEL_NAME + \"_\" + curr_dt + \".hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF8R-1oKvvXY",
        "outputId": "592463ff-2482-4d07-c750-c55bf7902297"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldjCMe75dbWS",
        "outputId": "e8dfdadb-3b41-4a79-eef0-33f053ca4d85"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    train_network(\"/content/drive/MyDrive/Music-Generator/06_27_2021__09_18_22/epoch:27-loss:0.7527-cat_acc:0.8634.hdf5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Gold_Silver_Rival_Battle.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Ff7-Cinco.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Rachel_Piano_tempofix.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Ff7-One_Winged.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Ff7-Jenova_Absolute.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Final_Fantasy_Matouyas_Cave_Piano.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/FF3_Battle_(Piano).mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/FF6epitaph_piano.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Kingdom_Hearts_Traverse_Town.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Fyw_piano.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Finalfantasy6fanfarecomplete.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/HighwindTakestotheSkies.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Eternal_Harvest.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Kingdom_Hearts_Dearly_Beloved.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/OTD5YA.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/FFIII_Edgar_And_Sabin_Piano.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/FF3_Third_Phase_Final_(Piano).mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/FFVII_BATTLE.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Fiend_Battle_(Piano).mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Ff4-BattleLust.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Fierce_Battle_(Piano).mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/AT.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/JENOVA.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/FFIXQuMarshP.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/DOS.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/FF4.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/BlueStone_LastDungeon.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/8.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Oppressed.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/0fithos.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Finalfantasy5gilgameshp.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Life_Stream.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Cids.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/EyesOnMePiano.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/FF8_Shuffle_or_boogie_pc.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Rydia_pc.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/In_Zanarkand.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/FFIX_Piano.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ff4-fight1.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ultros.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ff4-airship.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ff4pclov.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/VincentPiano.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/lurk_in_dark.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/thenightmarebegins.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/pkelite4.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/electric_de_chocobo.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/roseofmay-piano.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/figaro.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ff11_awakening_piano.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/cosmo.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/thoughts.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/fortresscondor.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/great_war.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/tifap.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/tpirtsd-piano.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ultimafro.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/relmstheme-piano.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Suteki_Da_Ne_(Piano_Version).mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/caitsith.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/decisive.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Zelda_Overworld.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/costadsol.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/redwings.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/Still_Alive-1.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/sandy.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/sera_.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/mining.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/dontbeafraid.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ff1battp.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/sobf.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/dayafter.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/waltz_de_choco.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ff4-town.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/bcm.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ff7-mainmidi.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ViviinAlexandria.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/path_of_repentance.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/gerudo.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/goldsaucer.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ff8-lfp.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ff4_piano_collections-main_theme.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/rufus.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ff6shap.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/braska.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/traitor.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/balamb.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/z_aeristhemepiano.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ff7themep.mid\n",
            "Parsing drive/MyDrive/Music-Generator/midi_songs/ahead_on_our_way_piano.mid\n",
            "Current datatime: 06_27_2021__13_58_40\n",
            "Vocabulary size: 1416\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/50\n",
            "446/446 [==============================] - 301s 650ms/step - loss: 0.7787 - categorical_accuracy: 0.8595\n",
            "Epoch 2/50\n",
            "446/446 [==============================] - 287s 644ms/step - loss: 0.7406 - categorical_accuracy: 0.8671\n",
            "Epoch 3/50\n",
            "446/446 [==============================] - 286s 642ms/step - loss: 0.7231 - categorical_accuracy: 0.8682\n",
            "Epoch 4/50\n",
            "446/446 [==============================] - 285s 639ms/step - loss: 0.7083 - categorical_accuracy: 0.8714\n",
            "Epoch 5/50\n",
            "446/446 [==============================] - 284s 636ms/step - loss: 0.7075 - categorical_accuracy: 0.8703\n",
            "Epoch 6/50\n",
            "446/446 [==============================] - 284s 636ms/step - loss: 0.6931 - categorical_accuracy: 0.8737\n",
            "Epoch 7/50\n",
            "446/446 [==============================] - 282s 633ms/step - loss: 0.6878 - categorical_accuracy: 0.8736\n",
            "Epoch 8/50\n",
            "446/446 [==============================] - 283s 635ms/step - loss: 0.6687 - categorical_accuracy: 0.8751\n",
            "Epoch 9/50\n",
            "446/446 [==============================] - 284s 637ms/step - loss: 0.6684 - categorical_accuracy: 0.8783\n",
            "Epoch 10/50\n",
            "446/446 [==============================] - 291s 652ms/step - loss: 0.6545 - categorical_accuracy: 0.8775\n",
            "Epoch 11/50\n",
            "446/446 [==============================] - 283s 635ms/step - loss: 0.6462 - categorical_accuracy: 0.8797\n",
            "Epoch 12/50\n",
            "446/446 [==============================] - 284s 636ms/step - loss: 0.6332 - categorical_accuracy: 0.8802\n",
            "Epoch 13/50\n",
            "446/446 [==============================] - 283s 635ms/step - loss: 0.6272 - categorical_accuracy: 0.8814\n",
            "Epoch 14/50\n",
            "446/446 [==============================] - 284s 636ms/step - loss: 0.6088 - categorical_accuracy: 0.8822\n",
            "Epoch 15/50\n",
            "446/446 [==============================] - 290s 649ms/step - loss: 0.6059 - categorical_accuracy: 0.8823\n",
            "Epoch 16/50\n",
            "446/446 [==============================] - 285s 639ms/step - loss: 0.5959 - categorical_accuracy: 0.8829\n",
            "Epoch 17/50\n",
            "446/446 [==============================] - 284s 636ms/step - loss: 0.5832 - categorical_accuracy: 0.8859\n",
            "Epoch 18/50\n",
            "446/446 [==============================] - 286s 640ms/step - loss: 0.5729 - categorical_accuracy: 0.8866\n",
            "Epoch 19/50\n",
            "446/446 [==============================] - 289s 649ms/step - loss: 0.5615 - categorical_accuracy: 0.8893\n",
            "Epoch 20/50\n",
            "446/446 [==============================] - 292s 655ms/step - loss: 0.5703 - categorical_accuracy: 0.8888\n",
            "Epoch 21/50\n",
            "446/446 [==============================] - 286s 642ms/step - loss: 0.5609 - categorical_accuracy: 0.8881\n",
            "Epoch 22/50\n",
            "446/446 [==============================] - 288s 646ms/step - loss: 0.5560 - categorical_accuracy: 0.8905\n",
            "Epoch 23/50\n",
            "446/446 [==============================] - 288s 645ms/step - loss: 0.5563 - categorical_accuracy: 0.8898\n",
            "Epoch 24/50\n",
            "446/446 [==============================] - 282s 632ms/step - loss: 0.5499 - categorical_accuracy: 0.8925\n",
            "Epoch 25/50\n",
            "446/446 [==============================] - 284s 636ms/step - loss: 0.5432 - categorical_accuracy: 0.8915\n",
            "Epoch 26/50\n",
            "446/446 [==============================] - 284s 636ms/step - loss: 0.5392 - categorical_accuracy: 0.8947\n",
            "Epoch 27/50\n",
            "446/446 [==============================] - 285s 640ms/step - loss: 0.5357 - categorical_accuracy: 0.8938\n",
            "Epoch 28/50\n",
            "446/446 [==============================] - 286s 641ms/step - loss: 0.5342 - categorical_accuracy: 0.8948\n",
            "Epoch 29/50\n",
            "446/446 [==============================] - 288s 644ms/step - loss: 0.5269 - categorical_accuracy: 0.8949\n",
            "Epoch 30/50\n",
            "446/446 [==============================] - 285s 638ms/step - loss: 0.5247 - categorical_accuracy: 0.8950\n",
            "Epoch 31/50\n",
            "446/446 [==============================] - 284s 637ms/step - loss: 0.5242 - categorical_accuracy: 0.8956\n",
            "Epoch 32/50\n",
            "446/446 [==============================] - 284s 636ms/step - loss: 0.5171 - categorical_accuracy: 0.8957\n",
            "Epoch 33/50\n",
            "446/446 [==============================] - 284s 636ms/step - loss: 0.5181 - categorical_accuracy: 0.8969\n",
            "Epoch 34/50\n",
            "446/446 [==============================] - 285s 640ms/step - loss: 0.5099 - categorical_accuracy: 0.8985\n",
            "Epoch 35/50\n",
            "446/446 [==============================] - 289s 648ms/step - loss: 0.5052 - categorical_accuracy: 0.9005\n",
            "Epoch 36/50\n",
            "446/446 [==============================] - 292s 654ms/step - loss: 0.5167 - categorical_accuracy: 0.8985\n",
            "Epoch 37/50\n",
            "446/446 [==============================] - 292s 655ms/step - loss: 0.5154 - categorical_accuracy: 0.8999\n",
            "Epoch 38/50\n",
            "446/446 [==============================] - 294s 660ms/step - loss: 0.5262 - categorical_accuracy: 0.8971\n",
            "Epoch 39/50\n",
            "446/446 [==============================] - 295s 660ms/step - loss: 0.5294 - categorical_accuracy: 0.8985\n",
            "Epoch 40/50\n",
            "446/446 [==============================] - 294s 660ms/step - loss: 0.5348 - categorical_accuracy: 0.8976\n",
            "Epoch 41/50\n",
            "446/446 [==============================] - 296s 664ms/step - loss: 0.5329 - categorical_accuracy: 0.8983\n",
            "Epoch 42/50\n",
            "446/446 [==============================] - 292s 655ms/step - loss: 0.5405 - categorical_accuracy: 0.8993\n",
            "Epoch 43/50\n",
            "446/446 [==============================] - 289s 648ms/step - loss: 0.5395 - categorical_accuracy: 0.8994\n",
            "Epoch 44/50\n",
            "446/446 [==============================] - 289s 649ms/step - loss: 0.5407 - categorical_accuracy: 0.8998\n",
            "Epoch 45/50\n",
            "446/446 [==============================] - 289s 647ms/step - loss: 0.5506 - categorical_accuracy: 0.8990\n",
            "Epoch 46/50\n",
            "446/446 [==============================] - 288s 645ms/step - loss: 0.5512 - categorical_accuracy: 0.9003\n",
            "Epoch 47/50\n",
            "446/446 [==============================] - 287s 643ms/step - loss: 0.5511 - categorical_accuracy: 0.8992\n",
            "Epoch 48/50\n",
            "446/446 [==============================] - 287s 645ms/step - loss: 0.5355 - categorical_accuracy: 0.9031\n",
            "Epoch 49/50\n",
            "446/446 [==============================] - 288s 645ms/step - loss: 0.5435 - categorical_accuracy: 0.9016\n",
            "Epoch 50/50\n",
            "121/446 [=======>......................] - ETA: 3:30 - loss: 0.4597 - categorical_accuracy: 0.9135"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17aoZKDPS5th"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    train_network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shQD1ehpm7rK"
      },
      "source": [
        "import pickle\n",
        "import numpy\n",
        "from music21 import instrument, note, stream, chord\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.layers import Activation\n",
        "from keras.models import load_model\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IS_ON_GOOGLE_COLAB = True\n",
        "except:\n",
        "  IS_ON_GOOGLE_COLAB = False\n",
        "\n",
        "GOOGLE_COLAB_ROOT = \"drive/MyDrive/Music-Generator/\"\n",
        "GENERATED_MODEL_PATH = \"generated_models/cpc_06_25_2021__09_42_21.hdf5\"\n",
        "DATA_NOTES_DIR = \"data/notes\"\n",
        "\n",
        "if IS_ON_GOOGLE_COLAB:\n",
        "\n",
        "    GENERATED_MODEL_PATH = GOOGLE_COLAB_ROOT + GENERATED_MODEL_PATH\n",
        "    DATA_NOTES_DIR = GOOGLE_COLAB_ROOT + DATA_NOTES_DIR\n",
        "\n",
        "def generate(filename):\n",
        "    \"\"\" Generate a piano midi file \"\"\"\n",
        "    #load the notes used to train the model\n",
        "    with open(DATA_NOTES_DIR, 'rb') as filepath:\n",
        "        notes = pickle.load(filepath)\n",
        "\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    # Get all pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
        "    # model = create_network(normalized_input, n_vocab)\n",
        "    model = load_model(GENERATED_MODEL_PATH)\n",
        "\n",
        "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
        "    create_midi(prediction_output, filename)\n",
        "\n",
        "def prepare_sequences(notes, pitchnames, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    # map between notes and integers and back\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    sequence_length = 100\n",
        "    network_input = []\n",
        "    # output = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        # output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    normalized_input = normalized_input / float(n_vocab)\n",
        "\n",
        "    return (network_input, normalized_input)\n",
        "\n",
        "def create_network(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    # Load the weights to each node\n",
        "    model.load_weights(GENERATED_MODEL_PATH)\n",
        "\n",
        "    return model\n",
        "\n",
        "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    start = numpy.random.randint(0, len(network_input)-1) #randomowa tablica intów\n",
        "\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames)) #int -> nuta dict\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = numpy.argmax(prediction)\n",
        "        result = int_to_note[index]\n",
        "        prediction_output.append(result)\n",
        "\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output\n",
        "\n",
        "def create_midi(prediction_output, file_path):\n",
        "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
        "        from the notes \"\"\"\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(current_note)\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp=file_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYOWNLzRm9J4"
      },
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    generate()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}